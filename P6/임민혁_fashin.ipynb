{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting tensorflow==1.15\n",
      "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 412.3 MB 32 kB/s s eta 0:00:01�█████████▉                 | 191.8 MB 17.0 MB/s eta 0:00:13/s eta 0:00:13███████████████           | 271.7 MB 10.3 MB/s eta 0:00:14��██▍     | 339.9 MB 57.3 MB/s eta 0:00:02�██ | 399.1 MB 58.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
      "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 57.3 MB/s eta 0:00:01        | 2.5 MB 57.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (1.18.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (0.34.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (1.27.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (0.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (1.15.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (1.12.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (1.0.8)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (0.9.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (3.12.3)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
      "\u001b[K     |████████████████████████████████| 503 kB 51.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (3.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (47.3.1.post20200622)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.1.0\n",
      "    Uninstalling tensorboard-2.1.0:\n",
      "      Successfully uninstalled tensorboard-2.1.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.1.0\n",
      "    Uninstalling tensorflow-estimator-2.1.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.1.0\n",
      "    Uninstalling tensorflow-2.1.0:\n",
      "      Successfully uninstalled tensorflow-2.1.0\n",
      "Successfully installed tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow==1.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주의! 이 곳에서 반드시 커널을 restart시키십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for training on gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 26421880 bytes.\n",
      "Extracting data/fashion/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 29515 bytes.\n",
      "Extracting data/fashion/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 4422102 bytes.\n",
      "Extracting data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 5148 bytes.\n",
      "Extracting data/fashion/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets('data/fashion',one_hot=True, source_url='http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 30164\r\n",
      "-rw------- 1 wsuser watsonstudio  4422102 Apr  2 15:24 t10k-images-idx3-ubyte.gz\r\n",
      "-rw------- 1 wsuser watsonstudio     5148 Apr  2 15:24 t10k-labels-idx1-ubyte.gz\r\n",
      "-rw------- 1 wsuser watsonstudio 26421880 Apr  2 15:23 train-images-idx3-ubyte.gz\r\n",
      "-rw------- 1 wsuser watsonstudio    29515 Apr  2 15:24 train-labels-idx1-ubyte.gz\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l data/fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (images) shape: (55000, 784)\n",
      "Training set (labels) shape: (55000, 10)\n",
      "Test set (images) shape: (10000, 784)\n",
      "Test set (labels) shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Shapes of training set\n",
    "print(\"Training set (images) shape: {shape}\".format(shape=data.train.images.shape))\n",
    "print(\"Training set (labels) shape: {shape}\".format(shape=data.train.labels.shape))\n",
    "\n",
    "# Shapes of test set\n",
    "print(\"Test set (images) shape: {shape}\".format(shape=data.test.images.shape))\n",
    "print(\"Test set (labels) shape: {shape}\".format(shape=data.test.labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of target classes\n",
    "label_dict = {\n",
    " 0: 'T-shirt/top',\n",
    " 1: 'Trouser',\n",
    " 2: 'Pullover',\n",
    " 3: 'Dress',\n",
    " 4: 'Coat',\n",
    " 5: 'Sandal',\n",
    " 6: 'Shirt',\n",
    " 7: 'Sneaker',\n",
    " 8: 'Bag',\n",
    " 9: 'Ankle boot',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '(Label: Ankle boot)')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "curr_img = np.reshape(data.train.images[0], (28,28))\n",
    "curr_lbl = np.argmax(data.train.labels[0,:])\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(data.test.images[0], (28,28))\n",
    "curr_lbl = np.argmax(data.test.labels[0,:])\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40784317, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03921569, 0.9568628 ,\n",
       "       0.8588236 , 0.9803922 , 0.80392164, 0.7803922 , 0.8196079 ,\n",
       "       0.79215693, 0.8196079 , 0.82745105, 0.7411765 , 0.83921576,\n",
       "       0.8078432 , 0.8235295 , 0.7843138 , 0.8313726 , 0.6039216 ,\n",
       "       0.94117653, 0.81568635, 0.8588236 , 0.54901963, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.08235294, 1.        , 0.8705883 , 0.9333334 ,\n",
       "       0.72156864, 0.8235295 , 0.75294125, 0.8078432 , 0.8196079 ,\n",
       "       0.8235295 , 0.7411765 , 0.8352942 , 0.82745105, 0.8196079 ,\n",
       "       0.75294125, 0.8941177 , 0.60784316, 0.8862746 , 0.9333334 ,\n",
       "       0.9450981 , 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.14509805,\n",
       "       0.9607844 , 0.8862746 , 0.9450981 , 0.5882353 , 0.7725491 ,\n",
       "       0.7411765 , 0.8000001 , 0.8196079 , 0.8235295 , 0.7176471 ,\n",
       "       0.8352942 , 0.8352942 , 0.78823537, 0.72156864, 0.8431373 ,\n",
       "       0.57254905, 0.8470589 , 0.92549026, 0.882353  , 0.6039216 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.227451  , 0.93725497, 0.89019614,\n",
       "       1.        , 0.61960787, 0.7568628 , 0.76470596, 0.8000001 ,\n",
       "       0.8196079 , 0.8352942 , 0.7058824 , 0.8117648 , 0.85098046,\n",
       "       0.7803922 , 0.7607844 , 0.82745105, 0.61960787, 0.8588236 ,\n",
       "       0.92549026, 0.8470589 , 0.5921569 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.26666668, 0.91372555, 0.8862746 , 0.95294124, 0.54509807,\n",
       "       0.7843138 , 0.7568628 , 0.80392164, 0.8235295 , 0.81568635,\n",
       "       0.7058824 , 0.80392164, 0.8313726 , 0.7960785 , 0.7686275 ,\n",
       "       0.8470589 , 0.6156863 , 0.7019608 , 1.        , 0.8470589 ,\n",
       "       0.60784316, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.31764707, 0.882353  ,\n",
       "       0.87843144, 0.82745105, 0.5411765 , 0.8588236 , 0.7254902 ,\n",
       "       0.78823537, 0.8352942 , 0.8117648 , 0.7725491 , 0.8862746 ,\n",
       "       0.8313726 , 0.7843138 , 0.74509805, 0.8431373 , 0.7176471 ,\n",
       "       0.3529412 , 1.        , 0.82745105, 0.5764706 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.35686275, 0.8235295 , 0.90196085, 0.61960787,\n",
       "       0.44705886, 0.80392164, 0.73333335, 0.81568635, 0.8196079 ,\n",
       "       0.8078432 , 0.7568628 , 0.8235295 , 0.82745105, 0.8000001 ,\n",
       "       0.76470596, 0.8000001 , 0.70980394, 0.09019608, 1.        ,\n",
       "       0.8352942 , 0.61960787, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.34117648,\n",
       "       0.80392164, 0.909804  , 0.427451  , 0.6431373 , 1.        ,\n",
       "       0.83921576, 0.87843144, 0.8705883 , 0.8235295 , 0.7725491 ,\n",
       "       0.83921576, 0.882353  , 0.8705883 , 0.82745105, 0.86274517,\n",
       "       0.85098046, 0.        , 0.9176471 , 0.8470589 , 0.6627451 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.36078432, 0.8352942 , 0.909804  ,\n",
       "       0.57254905, 0.01960784, 0.5254902 , 0.5921569 , 0.63529414,\n",
       "       0.6666667 , 0.7176471 , 0.7137255 , 0.6431373 , 0.6509804 ,\n",
       "       0.69803923, 0.63529414, 0.6117647 , 0.38431376, 0.        ,\n",
       "       0.94117653, 0.882353  , 0.8235295 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.16862746, 0.6431373 , 0.8078432 , 0.5529412 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.49803925, 0.4901961 ,\n",
       "       0.29803923, 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train.images[0][500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(data.train.images[0]))\n",
    "print(np.min(data.train.images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape training and testing image\n",
    "train_X = data.train.images.reshape(-1, 28, 28, 1)\n",
    "test_X = data.test.images.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y =data.train.labels\n",
    "test_y = data.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 10), (10000, 10))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "training_iters = 5\n",
    "learning_rate = 0.001\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data input (img shape: 28*28)\n",
    "n_input = 28\n",
    "\n",
    "# MNIST total classes (0-9 digits)\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#both placeholders are of type float\n",
    "x = tf.placeholder(\"float\", [None, 28,28,1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.sigmoid(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'wc1': tf.get_variable('W0', shape=(3,3,1,32), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'wc2': tf.get_variable('W1', shape=(3,3,32,64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'wc3': tf.get_variable('W2', shape=(3,3,64,128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'wd1': tf.get_variable('W3', shape=(4*4*128,128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'out': tf.get_variable('W6', shape=(128,n_classes), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "}\n",
    "biases = {\n",
    "    'bc1': tf.get_variable('B0', shape=(32), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc2': tf.get_variable('B1', shape=(64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc3': tf.get_variable('B2', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bd1': tf.get_variable('B3', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'out': tf.get_variable('B4', shape=(10), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases):  \n",
    "\n",
    "    # here we call the conv2d function we had defined above and pass the input image x, weights wc1 and bias bc1.\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 14*14 matrix.\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    # here we call the conv2d function we had defined above and pass the input image x, weights wc2 and bias bc2.\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 7*7 matrix.\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 4*4.\n",
    "    conv3 = maxpool2d(conv3, k=2)\n",
    "\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.sigmoid(fc1)\n",
    "    # Output, class prediction\n",
    "    # finally we multiply the fully connected layer with the weights and add a bias term.\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = conv_net(x, weights, biases)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, you check whether the index of the maximum value of the predicted image is equal to the actual labeled image. And both will be a column vector.\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "#calculate accuracy across all the given images and average them out.\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss= 2.305193, Training Accuracy= 0.07031\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.10000\n",
      "Iter 1, Loss= 2.302926, Training Accuracy= 0.07031\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.09720\n",
      "Iter 2, Loss= 2.302892, Training Accuracy= 0.09375\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "    for i in range(training_iters):\n",
    "        for batch in range(len(train_X)//batch_size):\n",
    "            batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
    "            batch_y = train_y[batch*batch_size:min((batch+1)*batch_size,len(train_y))]    \n",
    "            # Run optimization op (backprop).\n",
    "                # Calculate batch loss and accuracy\n",
    "            opt = sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x, y: batch_y})\n",
    "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc))\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        # Calculate accuracy for all 10000 mnist test images\n",
    "        test_acc,valid_loss = sess.run([accuracy,cost], feed_dict={x: test_X,y : test_y})\n",
    "        train_loss.append(loss)\n",
    "        test_loss.append(valid_loss)\n",
    "        train_accuracy.append(acc)\n",
    "        test_accuracy.append(test_acc)\n",
    "        print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_loss)), train_loss, 'b', label='Training loss')\n",
    "plt.plot(range(len(train_loss)), test_loss, 'r', label='Test loss')\n",
    "plt.title('Training and Test loss')\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_loss)), train_accuracy, 'b', label='Training Accuracy')\n",
    "plt.plot(range(len(train_loss)), test_accuracy, 'r', label='Test Accuracy')\n",
    "plt.title('Training and Test Accuracy')\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_loss)), train_accuracy, 'b', label='Training Accuracy')\n",
    "plt.plot(range(len(train_loss)), test_loss, 'r', label='Test loss')\n",
    "plt.title('Training Accuracy vs. Test Loss')\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
